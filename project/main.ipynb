{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "algorithms :\n",
    "\n",
    "    SAE training :\n",
    "\n",
    "dataset = base model dataset\n",
    "activations = truncated_model(dataset)\n",
    "SAE fit activations\n",
    "\n",
    "    probe training :\n",
    "\n",
    "dataset = string + label\n",
    "activations = truncated_model(dataset)\n",
    "    -> stop_at_layer (from transformer lens)\n",
    "optional : activations = SAE(activations)\n",
    "activations = trivial_normalisation(activations)\n",
    "\n",
    "dataset = activations + label\n",
    "loss = CCS or other\n",
    "probe = probe\n",
    "train probe\n",
    "\n",
    "test generalisation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens as tl\n",
    "\n",
    "from probes import LinearProbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "gpt2small = tl.HookedTransformer.from_pretrained(\"gpt2\")\n",
    "d_resid = gpt2small.cfg.d_model\n",
    "probe = LinearProbe(d_resid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2',\n",
       " 'gpt2-medium',\n",
       " 'gpt2-large',\n",
       " 'gpt2-xl',\n",
       " 'distilgpt2',\n",
       " 'facebook/opt-125m',\n",
       " 'facebook/opt-1.3b',\n",
       " 'facebook/opt-2.7b',\n",
       " 'facebook/opt-6.7b',\n",
       " 'facebook/opt-13b',\n",
       " 'facebook/opt-30b',\n",
       " 'facebook/opt-66b',\n",
       " 'EleutherAI/gpt-neo-125M',\n",
       " 'EleutherAI/gpt-neo-1.3B',\n",
       " 'EleutherAI/gpt-neo-2.7B',\n",
       " 'EleutherAI/gpt-j-6B',\n",
       " 'EleutherAI/gpt-neox-20b',\n",
       " 'stanford-crfm/alias-gpt2-small-x21',\n",
       " 'stanford-crfm/battlestar-gpt2-small-x49',\n",
       " 'stanford-crfm/caprica-gpt2-small-x81',\n",
       " 'stanford-crfm/darkmatter-gpt2-small-x343',\n",
       " 'stanford-crfm/expanse-gpt2-small-x777',\n",
       " 'stanford-crfm/arwen-gpt2-medium-x21',\n",
       " 'stanford-crfm/beren-gpt2-medium-x49',\n",
       " 'stanford-crfm/celebrimbor-gpt2-medium-x81',\n",
       " 'stanford-crfm/durin-gpt2-medium-x343',\n",
       " 'stanford-crfm/eowyn-gpt2-medium-x777',\n",
       " 'EleutherAI/pythia-14m',\n",
       " 'EleutherAI/pythia-31m',\n",
       " 'EleutherAI/pythia-70m',\n",
       " 'EleutherAI/pythia-160m',\n",
       " 'EleutherAI/pythia-410m',\n",
       " 'EleutherAI/pythia-1b',\n",
       " 'EleutherAI/pythia-1.4b',\n",
       " 'EleutherAI/pythia-2.8b',\n",
       " 'EleutherAI/pythia-6.9b',\n",
       " 'EleutherAI/pythia-12b',\n",
       " 'EleutherAI/pythia-70m-deduped',\n",
       " 'EleutherAI/pythia-160m-deduped',\n",
       " 'EleutherAI/pythia-410m-deduped',\n",
       " 'EleutherAI/pythia-1b-deduped',\n",
       " 'EleutherAI/pythia-1.4b-deduped',\n",
       " 'EleutherAI/pythia-2.8b-deduped',\n",
       " 'EleutherAI/pythia-6.9b-deduped',\n",
       " 'EleutherAI/pythia-12b-deduped',\n",
       " 'EleutherAI/pythia-70m-v0',\n",
       " 'EleutherAI/pythia-160m-v0',\n",
       " 'EleutherAI/pythia-410m-v0',\n",
       " 'EleutherAI/pythia-1b-v0',\n",
       " 'EleutherAI/pythia-1.4b-v0',\n",
       " 'EleutherAI/pythia-2.8b-v0',\n",
       " 'EleutherAI/pythia-6.9b-v0',\n",
       " 'EleutherAI/pythia-12b-v0',\n",
       " 'EleutherAI/pythia-70m-deduped-v0',\n",
       " 'EleutherAI/pythia-160m-deduped-v0',\n",
       " 'EleutherAI/pythia-410m-deduped-v0',\n",
       " 'EleutherAI/pythia-1b-deduped-v0',\n",
       " 'EleutherAI/pythia-1.4b-deduped-v0',\n",
       " 'EleutherAI/pythia-2.8b-deduped-v0',\n",
       " 'EleutherAI/pythia-6.9b-deduped-v0',\n",
       " 'EleutherAI/pythia-12b-deduped-v0',\n",
       " 'EleutherAI/pythia-160m-seed1',\n",
       " 'EleutherAI/pythia-160m-seed2',\n",
       " 'EleutherAI/pythia-160m-seed3',\n",
       " 'NeelNanda/SoLU_1L_v9_old',\n",
       " 'NeelNanda/SoLU_2L_v10_old',\n",
       " 'NeelNanda/SoLU_4L_v11_old',\n",
       " 'NeelNanda/SoLU_6L_v13_old',\n",
       " 'NeelNanda/SoLU_8L_v21_old',\n",
       " 'NeelNanda/SoLU_10L_v22_old',\n",
       " 'NeelNanda/SoLU_12L_v23_old',\n",
       " 'NeelNanda/SoLU_1L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_2L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_3L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_4L512W_C4_Code',\n",
       " 'NeelNanda/SoLU_6L768W_C4_Code',\n",
       " 'NeelNanda/SoLU_8L1024W_C4_Code',\n",
       " 'NeelNanda/SoLU_10L1280W_C4_Code',\n",
       " 'NeelNanda/SoLU_12L1536W_C4_Code',\n",
       " 'NeelNanda/GELU_1L512W_C4_Code',\n",
       " 'NeelNanda/GELU_2L512W_C4_Code',\n",
       " 'NeelNanda/GELU_3L512W_C4_Code',\n",
       " 'NeelNanda/GELU_4L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_1L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_2L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_3L512W_C4_Code',\n",
       " 'NeelNanda/Attn_Only_4L512W_C4_Code',\n",
       " 'NeelNanda/Attn-Only-2L512W-Shortformer-6B-big-lr',\n",
       " 'NeelNanda/SoLU_1L512W_Wiki_Finetune',\n",
       " 'NeelNanda/SoLU_4L512W_Wiki_Finetune',\n",
       " 'ArthurConmy/redwood_attn_2l',\n",
       " 'llama-7b-hf',\n",
       " 'llama-13b-hf',\n",
       " 'llama-30b-hf',\n",
       " 'llama-65b-hf',\n",
       " 'Llama-2-7b-hf',\n",
       " 'Llama-2-7b-chat-hf',\n",
       " 'Llama-2-13b-hf',\n",
       " 'Llama-2-13b-chat-hf',\n",
       " 'Baidicoot/Othello-GPT-Transformer-Lens',\n",
       " 'bert-base-cased',\n",
       " 'roneneldan/TinyStories-1M',\n",
       " 'roneneldan/TinyStories-3M',\n",
       " 'roneneldan/TinyStories-8M',\n",
       " 'roneneldan/TinyStories-28M',\n",
       " 'roneneldan/TinyStories-33M',\n",
       " 'roneneldan/TinyStories-Instruct-1M',\n",
       " 'roneneldan/TinyStories-Instruct-3M',\n",
       " 'roneneldan/TinyStories-Instruct-8M',\n",
       " 'roneneldan/TinyStories-Instruct-28M',\n",
       " 'roneneldan/TinyStories-Instruct-33M',\n",
       " 'roneneldan/TinyStories-1Layer-21M',\n",
       " 'roneneldan/TinyStories-2Layers-33M',\n",
       " 'roneneldan/TinyStories-Instuct-1Layer-21M',\n",
       " 'roneneldan/TinyStories-Instruct-2Layers-33M',\n",
       " 'stabilityai/stablelm-base-alpha-3b',\n",
       " 'stabilityai/stablelm-base-alpha-7b',\n",
       " 'stabilityai/stablelm-tuned-alpha-3b',\n",
       " 'stabilityai/stablelm-tuned-alpha-7b',\n",
       " 'bigscience/bloom-560m',\n",
       " 'bigcode/santacoder']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.loading_from_pretrained.OFFICIAL_MODEL_NAMES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
